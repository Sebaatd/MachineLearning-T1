{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2019 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Problemas de clasificación y regresión.\n",
    "* Regresión lineal ordinaria (mínimos cuadrados).\n",
    "* Selección de atributos y parámetros de regularización en regresión lineal (Ridge y Lasso).\n",
    "* Validación cruzada.\n",
    "* Reducción de dimensionalidad: PCA e ICA.\n",
    "* Selección de hiper-parámetros estructurales de modelos de aprendizaje.\n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 4 Octubre.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF393-II-2019]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Máquinas de aprendizaje aplicadas a la medicina  \n",
    "[2.](#segundo) Estimación de edad de personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Máquinas de aprendizaje aplicadas a la medicina\n",
    "En el area de la salud, diagnosticar la enfermedad de una persona de forma rápida y correcta puede llegar a salvarle la vida. Los encargados de realizar estos diagnósticos, son médicos que, observando exámenes y ciertos indicadores, pueden concluir qué enfermedad presenta el paciente. Si el médico se llegase a equivocar, aparte de que el paciente pueda perder la vida, el medico podría ser demandado por negligencia arriesgando años de cárcel o pagar sumas de dinero considerable, es por estas razones que es importante no cometer errores.  \n",
    "Pongámonos en el contexto de que usted es contratado para utilizar técnicas de aprendizaje de máquina para asistir en un problema médico como es la detección de enfermedades cardiacas. El diagnóstico de una enfermedad cardiaca se realiza a través de signos clínicos y resultados de pruebas médicas, los cuales usted deberá utilizar en busca del comportamiento normal y anormal de los pacientes, para así obtener un modelo que prediga si el paciente en efecto presenta una enfermedad o no.\n",
    "\n",
    "\n",
    "<img src=\"https://www.scripps.edu/_files/images/science-and-medicines/600x400_heart_illustration_xray.jpg\" width=\"35%\" />\n",
    "\n",
    "\n",
    "Los datos para trabajar junto a su documentación pueden ser descargados ejecutando los siguientes comandos en un terminal (*sistemas UNIX*):\n",
    "```\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.doc\n",
    "```\n",
    "\n",
    "---\n",
    "Cargue los datos a trabajar en un *dataframe* de pandas. Exprese las variables que tienen valores categóricos en su estructura original, para así tener una información más clara de lo que significa en un comienzo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Descomentar lo siguiente para ver warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "headers = ['age','sex','chest_pain','blood_p','serum','blood_s','electro','max_heart', 'angina','oldpeak','slope','vessel','thal','normal']\n",
    "df = pd.read_csv(\"heart.dat\", header=None, names=headers, sep=' ')\n",
    "df['sex'][df['sex'] == 0] = 'female'\n",
    "df['sex'][df['sex'] == 1] = 'male'\n",
    "df['chest_pain'][df['chest_pain'] == 1] = 'typical angina'\n",
    "df['chest_pain'][df['chest_pain'] == 2] = 'atypical angina'\n",
    "df['chest_pain'][df['chest_pain'] == 3] = 'non-anginal pain'\n",
    "df['chest_pain'][df['chest_pain'] == 4] = 'asymptomatic'\n",
    "df['blood_s'][df['blood_s'] == 0] = 'lower than 120mg/ml'\n",
    "df['blood_s'][df['blood_s'] == 1] = 'greater than 120mg/ml'\n",
    "df['electro'][df['electro'] == 0] = 'normal'\n",
    "df['electro'][df['electro'] == 1] = 'ST-T wave abnormality'\n",
    "df['electro'][df['electro'] == 2] = 'left ventricular hypertrophy'\n",
    "df['angina'][df['angina'] == 0] = 'no'\n",
    "df['angina'][df['angina'] == 1] = 'yes'\n",
    "df['slope'][df['slope'] == 1] = 'upsloping'\n",
    "df['slope'][df['slope'] == 2] = 'flat'\n",
    "df['slope'][df['slope'] == 3] = 'downsloping'\n",
    "df['thal'][df['thal'] == 3] = 'normal'\n",
    "df['thal'][df['thal'] == 6] = 'fixed defect'\n",
    "df['thal'][df['thal'] == 7] = 'reversable defect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Visualice los datos trabajados describiendo el comportamiento de las variables para entender el problema al que se enfrenta. ¿Qué ocurre con el comportamiento entre pacientes sanos y enfermos? Haga gráficos si estima conveniente (histogramas, boxplots, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 14 columns):\n",
      "age           270 non-null float64\n",
      "sex           270 non-null object\n",
      "chest_pain    270 non-null object\n",
      "blood_p       270 non-null float64\n",
      "serum         270 non-null float64\n",
      "blood_s       270 non-null object\n",
      "electro       270 non-null object\n",
      "max_heart     270 non-null float64\n",
      "angina        270 non-null object\n",
      "oldpeak       270 non-null float64\n",
      "slope         270 non-null object\n",
      "vessel        270 non-null float64\n",
      "thal          270 non-null object\n",
      "normal        270 non-null int64\n",
      "dtypes: float64(6), int64(1), object(7)\n",
      "memory usage: 29.6+ KB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "#Boxplots con valores cuantificables\n",
    "#age_boxplot = df.boxplot(column=['age'])\n",
    "hist = df.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Debido a que utilizaremos modelos lineales, necesitaremos una representación adecuada de los datos. Codifique las variables con valores categóricos para ser representados como *one hot vectors*, indicando con un 1 la presencia del atributo en cuestión. Por ejemplo, si un paciente tiene el atributo \"sex: female\", quedará codificado como [0,1], mientras que si tiene el atributo \"sex: male\", quedará como [1,0]. **Explique la importancia de éste paso.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** La importancia de representar las variables como *one hot vector* es que permite transformar una categoria en una forma binaria para poder entrenar el modelo; en otras palabras, la categoría se incluye como una *característica* al modelo. Si se conservara la representación inicial, las variables serían incompatibles para el modelo, ya que este necesita trabajar con valores numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir la presión sanguínea\n",
    "\n",
    "En primera instancia trabajaremos en el dominio de regresión para predecir el comportamiento de alguna de las variables involucradas con el fin de entender cómo se comportan y si es posible estimar alguna de ellas a partir de las otras. Como ayuda se le indica que una alta presión sanguínea (*blood preasure*) podría ser un indicador de riesgo en temas cardíacos, en específico, para el problema se le comenta la hipótesis de que el comportamiento anormal de la variable presión sanguínea es un buen indicador para la detección de enfermedades cardíacas. \n",
    "Su objetivo dada esta información será la de predecir el comportamiento de esta variable en función de las otras, para luego detectar qué tan distante es el valor real al valor predecido y así detectar las enfermedades.\n",
    "\n",
    "\n",
    "> c) Extraiga la información de la enfermedad cardíaca (*clase binaria*) además de la variable continua que nos intereserá predecir en esta instancia (*target*) con un modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arreglo de elementos donde 0 indica ausencia de normal y 1 presencia de normal\n",
    "class_label = df.pop(\"normal\").values -1 # 0 means absence, 1 means presence\n",
    "\n",
    "#Arreglo de 270 elementos con los valores de la presión sanguínea de cada individuo \n",
    "reg_label = df.pop(\"blood_p\").values\n",
    "\n",
    "#Arreglo con información completa de cada individuo\n",
    "X_data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) Cree un conjunto de pruebas para evaluar los modelos construidos en el problema. Extraiga el 30\\% de los datos del conjunto total para representar el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "mask_test = np.random.rand(X_data.shape[0]) < 0.30\n",
    "...\n",
    "#Datos a considerar para el entrenamiento\n",
    "X_train = X_data[~mask_test] \n",
    "#Datos a considerar para la prueba\n",
    "X_test = X_data[mask_test] \n",
    "...\n",
    "reg_label_train = reg_label[~mask_test] \n",
    "reg_label_test = reg_label[mask_test]\n",
    "...\n",
    "class_label_train = class_label[~mask_test] \n",
    "class_label_test = class_label[mask_test]\n",
    "...\n",
    "print(\"Train: \",X_train.shape)\n",
    "print(\"Test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Realice una estandarización normal de los datos de entrada al modelo (*input*). **Comente la importancia/conveniencia de realizar este paso**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "Xstd_train = std.transform(X_train) \n",
    "Xstd_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Realice una regresión lineal de mı́nimos cuadrados básica para predecir el nivel de presión sanguínea. Mida los errores de predicción para cada dato en el conjunto de entrenamiento. Utilizando un *quantile-quantile plot* determine si es razonable la hipótesis de normalidad sobre los residuos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(Xstd_train, reg_label_train)\n",
    "...\n",
    "reg_pred_train = model.predict(Xstd_train)\n",
    "reg_pred_test = model.predict(Xstd_test)\n",
    "\n",
    "#Error de predicción = Valor real - Predicción\n",
    "error = reg_label_train - reg_pred_train\n",
    "\n",
    "#No se cual variable usar xD\n",
    "stats.probplot(error, dist=\"norm\", plot=pylab)\n",
    "pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "# Generate some data for this demonstration.\n",
    "#data = norm.rvs(10.0, 2.5, size=500)\n",
    "\n",
    "# Fit a normal distribution to the data:\n",
    "mu, std = norm.fit(error)\n",
    "\n",
    "# Plot the histogram.\n",
    "plt.hist(error, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# Plot the PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Resultados de ajuste: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** Considerando los residuos del modelo, al hacer QQPlot se puede observar que la normalización produce una distribución que está levemente sesgada a la derecha; esto se puede comprobar construyendo un histograma con los residuos (segundo gráfico), donde se observa que hay datos levemente concentrados a la izquierda, produciendo el sesgo mencionado. Por tanto...\n",
    "\n",
    "https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) Construya una tabla con los pesos, Z-score y F-score correspondientes a cada predictor (variable), compare estos valores. ¿Qué sucede si hacemos un raking de los atributos en base al peso obtenido en la regresión? ¿Qué variables están más correlacionadas con la respuesta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = list(df.columns)\n",
    "#cols.remove('ID')\n",
    "#df[cols]\n",
    "\n",
    "#cols = list(df.columns)\n",
    "#df[cols]\n",
    "\n",
    "#for col in cols:\n",
    "#    col_zscore = col + '_zscore'\n",
    "#    df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> h) Para evaluar la calidad de las predicciones del modelo sobre el problema utilice el error absoluto medio (*mean absolute error*). Comente los resultados sobre en ambos conjuntos y la interpretación que se le da a la métrica de evaluación en el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"MAE train: \", mean_absolute_error(reg_label_train, reg_pred_train))\n",
    "print(\"MAE test: \", mean_absolute_error(reg_label_test, reg_pred_test))\n",
    "\n",
    "print(\"MSE train: \", mean_squared_error(reg_label_train, reg_pred_train))\n",
    "print(\"MSE test: \", mean_squared_error(reg_label_test, reg_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** Al observar los errores absolutos medios (MAE) sobre ambos conjuntos se puede notar que la diferencia entre ambos es aproximadamente una unidad ($12.5$ vs $13.7$); esto indica que las predicciones son similares en calidad y es práctico separar el dataset en dos conjuntos, uno para entrenamiento y otro de prueba. En este tipo de error una diferencia de esa magnitud es aceptable porque MAE no penaliza tan bruscamente errores fuera de lo normal (outliers).\n",
    "\n",
    "Por otra parte, en el caso del error cuadrático medio (MSE) existe una mayor diferencia, pero se debe recordar que está calculado con el cuadrado de las diferencias entre el valor real y la predicción; por tanto, un error de 4 unidades aproximadamente no es grave y quiere decir que ambos conjuntos obtienen, en general, predicciones similares. Además, MSE es más sensitivo a los outliers, por lo que se esperaría una mayor diferencia,\n",
    "\n",
    "Sin embargo, observando nuevamente el error absoluto medio del conjunto de entrenamiento, $12.5$ no es un valor menor para la magnitud que tiene este predictor. Esto podría influir negativamente en aquellos casos que están al límite de significar una enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> i) Estime la calidad del modelo usando validación cruzada con un número de *fold* igual a $K=1$ (*leave-one-out*) y $K=5$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Compare esta estimación *vs* la calidad real (en conjunto de pruebas) y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def crossValidation(K):\n",
    "    \n",
    "    if K == 1:\n",
    "        kf = LeaveOneOut()\n",
    "    else:\n",
    "        kf = KFold(n_splits=K)\n",
    "        \n",
    "    mse_cv = 0\n",
    "    for train, val in kf.split(Xstd_train):\n",
    "        linreg = LinearRegression(fit_intercept=True)\n",
    "        linreg.fit(Xstd_train[train], reg_label_train[train])\n",
    "        yhat_kfold_val = linreg.predict(Xstd_train[val])\n",
    "        mse_fold =  np.mean( np.square(yhat_kfold_val - reg_label_train[val]) )\n",
    "        mse_cv += mse_fold\n",
    "        \n",
    "    if K == 1:\n",
    "        mse_cv = mse_cv / kf.get_n_splits(Xstd_train)\n",
    "    else:\n",
    "        mse_cv = mse_cv / K\n",
    "    \n",
    "    return mse_cv\n",
    "\n",
    "print(\"Validación cruzada con K = 1 folds: \", crossValidation(1))\n",
    "print(\"Validación cruzada con K = 5 folds: \", crossValidation(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** *No sé si estará bien calculado con 1 fold*. Comparando las estimaciones de calidad obtenidas con Cross-Validation es posible observar que cuando se usa solo un *fold* se obtiene un MSE promedio de $337.326$; mientras que para 5 folds, se obtiene un MSE promedio de $362.101$. En general, se podría decir que con uno solo fold se obtiene mejor calidad, ya que el MSE obtenido es menor; sin embargo, una razón de esto es que la cantidad de datos usados no es grande. Cuando se utilizan más folds, se obtienen varianzas y sesgos más grandes, lo que produce estimar una menor calidad.\n",
    "\n",
    "Por otra parte, comparando las estimaciones con la calidad real obtenida anteriormente ($263.185$) se ve que hay una diferencia no menor. Recordar que el MSE se calcula con las diferencias al cuadrado entre el valor real y predecido, por tanto, una diferencia de $50$ o más no es poco, pero pareciera ser aceptable para decir que la calidad del modelo según la estimación presenta no es perfecta.\n",
    "\n",
    "https://stats.stackexchange.com/questions/154830/10-fold-cross-validation-vs-leave-one-out-cross-validation\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation\n",
    "\n",
    "https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> j) Debido a la creación de varias columnas *dummys* en el punto b), experimente con técnicas de regularización para mejorar el desempeño de su modelo. Para ésto ajuste un modelo lineal utilizando \"*Ridge Regression*\", es decir, regularizando con la norma $l_2$, varíe los parámetros de regularización si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alphas_ = np.logspace(5, 0, base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True, solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xstd_train, reg_label_train)\n",
    "    coefs.append(model.coef_)\n",
    "    \n",
    "names_regressors = df.columns\n",
    "plt.figure(figsize=(15,7))\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** La idea de regulizar con la norma $l_2$ es que se intenta mitigar la multicolinealidad de la regresión lineal realizada en el modelo, es decir, se intenta reducir el efecto de correlación entre las variables (parámetros). En este caso, se busca mitigar el efecto de las columnas *dummys* agregadas anteriormente con el efecto de reducir el overfitting y obtener modelo con mejor capacidad predictiva.\n",
    "\n",
    "En el gráfico se ilustra como las variables predictoras se van estabilizando a la derecha a medida que el parámetro de regularización (Ridge Parameter) va aumentando...\n",
    "\n",
    "https://en.wikipedia.org/wiki/Tikhonov_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> k) Ahora experimente regularizando con la norma $l_1$, lo que corresponde a utilizar el método \"*Lasso*\". Vuelva a realizar el gráfico mostrando los coeficientes obtenidos, describa lo que observa. ¿Es más efectivo *Lasso* para seleccionar atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas_ = np.logspace(2,-2,base=10)\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True)\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xstd_train, reg_label_train)\n",
    "    coefs.append(model.coef_)\n",
    "\n",
    "names_regressors = df.columns\n",
    "plt.figure(figsize=(15,7))\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.title('Regularization Path LASSO')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** Cuando se utiliza regularización utilizando el método *Lasso* se observa que la estandarización para las variables predictorias es más brusca que al utilizar regularización con método *Ridge*. En este caso se observa que las variables se estabilizan (cuando el coeficiente de estandarización es 0) entre los parámetros $0$ y $1$; mientras que con la norma $l_2$, la estabilización sucedía gradualmente entre $0$ y $5$. A pesar de que el método Lasso es similar a Ridge, la diferencia está en que la función objetivo de optimización agrega una suma de valores absolutos de los coeficientes, lo que permite llegar a que todos los sean cero antes (*sparsity*). En vista a la selección de parámetros, estos valores que se estandarizan antes pueden ser descartados del modelo; en este caso, se observa que los parámetros más relevantes para el modelo son *age*, *oldpeak*,  *chest_pain_atypical angina*, *blood_s_greather than 120mg/ml*, entre otros.\n",
    "\n",
    "En general, para discendir cuál método resulta más efectivo depende del caso. La idea de usar Ridge es que puede prevenir el *overfitting*, sin embargo, resulta complejo cuando se tiene una cantidad grandes de parámetros. Por el otro lado, el método Lasso genera una escasez de parámetros (*sparsity*), lo que en este caso es muy efectivo porque facilita el trabajo de selección de parámetros, ya que la cantidad en este caso es grande. Por tanto, la regularización $l_2$ es más efectiva para este caso.\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> l) Evalúe la calidad de estos dos modelos en ambos conjuntos a distintos valores del parámetro de regularización. Haga uso de la *widget* interactiva de *ipython*. Comente ¿Con qué valor de *alpha* se quedaría en cada caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "    \n",
    "def train_model(param):\n",
    "    #model = #define the model (Ridge and Lasso)\n",
    "    ridge_model = Ridge(fit_intercept=True, solver='svd')\n",
    "    lasso_model = Lasso(fit_intercept=True)\n",
    "    \n",
    "    A = 10**(param)\n",
    "    print(\"Param alpha = \",A)\n",
    "    ridge_model.set_params(alpha=A)\n",
    "    ridge_model.fit(Xstd_train, reg_label_train)\n",
    "    \n",
    "    lasso_model.set_params(alpha=A)\n",
    "    lasso_model.fit(Xstd_train, reg_label_train)\n",
    "    \n",
    "    print(\"MSE train (Ridge Model): \", mean_squared_error(reg_label_train, ridge_model.predict(Xstd_train) ))\n",
    "    print(\"MSE test (Ridge Model): \", mean_squared_error(reg_label_test, ridge_model.predict(Xstd_test) ))\n",
    "    print(\"MSE train (Lasso Model): \", mean_squared_error(reg_label_train, lasso_model.predict(Xstd_train) ))\n",
    "    print(\"MSE test (Lasso Model): \", mean_squared_error(reg_label_test, lasso_model.predict(Xstd_test) ))   \n",
    "    \n",
    "    '''\n",
    "    model.set_params(alpha=A)\n",
    "    model.fit(Xstd_train, reg_label_train)\n",
    "    print(\"MSE train: \", mean_squared_error(reg_label_train, model.predict(Xstd_train) ))\n",
    "    print(\"MSE test: \", mean_squared_error(reg_label_test, model.predict(Xstd_test) ))\n",
    "    '''\n",
    "    \n",
    "p_min = -10 #define your range\n",
    "p_max = 10 #define your range\n",
    "\n",
    "interactive(train_model, param=(p_min,p_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:** Se puede observar que para ciertos valores de parámetro, los errores para ambos modelos dejan de crecer. En el caso del modelo Ridge, después de $10^5$ el error solo crece en los decimales, llegando a ser despreciable para valores más altos ya que no alcanza ni a variar a la unidad. Por otra parte, cuando el valor de $\\alpha$ es $10^1$, el error del modelo Lasso simplemente deja de crecer, lo que se demuestra con el gráfico anterior cuando se logra la estabilización de todos los coeficientes entre valores de parámetros de $10^0$ y $10^1$.\n",
    "\n",
    "Por tanto, para el modelo Ridge se usaría un $\\alpha$ de $10^5$, mientras que para el modelo Lasso un $\\alpha$ de $10^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> m) De manera más estricta un médico le solicita un modelo que solo cuente con 5 características (variables) para predecir el nivel de presión sanguínea. Usted bien conoce un método que selecciona características de manera iterativa (*greedy*), con la idea de que la característica seleccionada tenga el mejor aporte sobre el desempeño del modelo. Construya una función que implemente *Forward Step-wise Selection* (FSS) sobre el modelo de regresión lineal clásico.  Para seleccionar localmente una característica, **proponga/implemente un criterio distinto al utilizado en el código de ejemplo** (**no** utilice el conjunto de pruebas). Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    \n",
    "    #Para python2\n",
    "    #remaining = range(0, p)\n",
    "    \n",
    "    #Para python3\n",
    "    myrange = range(0, p)\n",
    "    remaining = list(range(0, p))\n",
    "\n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = LinearRegression(fit_intercept=True, n_jobs=1)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train =  predictions_train - y\n",
    "            error_candidate =  np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((error_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print(\"selected = %s ...\"%names_x[best_candidate])\n",
    "        print(\"totalvars=%d, mse = %f\"%(len(indexes),best_new_score))\n",
    "    return selected\n",
    "\n",
    "features_fss = fss(Xstd_train, reg_label_train, names_regressors)\n",
    "need_feat = features_fss[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> n) Realice otra modificación al algoritmo FSS anterior, en donde se deba entrenar el modelo predictor una sola vez. Cree alguna huerística de selección que le permita realizar ésto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> o) Realice una modificación a los datos y agregue entre 10 a 100 atributos falsos, es decir, atributos aleatorios generados que no tienen relación con la variable de predicción (*target*). Para ésto utilice una distribución normal con valor esperado diferente de 0 y una cierta desviación estándar. Utilice alguna de las técnicas de selección de atributos (Ridge, Lasso, FSS) para evaluar la efectividad en eliminar estos atributos falsos ¿Depende del nivel de ruido (desviación estándar)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = #number of fake features\n",
    "F = np.random.normal(loc = mu, scale = std, size=(N,D) ) #fake features\n",
    "X_new_train= np.concatenate([Xstd_train, F], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar una enfermedad \n",
    "Con toda la información obtenida de la experimentación previa, deberá hacer la predicción de la enfermedad cardíaca, ésto es un problema binario de clasificación de dos clases (presencia o ausencia de la enfermedad). Para explorar la hipótesis que le fue entregada en un inicio, de que el comportamiento anormal (*outlier*) de presión sanguínea sobre las personas es un indicio de alguna enfermedad, deberá utilizar los datos de los pacientes que se encuentran sanos (comportamiento normal).\n",
    "\n",
    "> p) Entrene un modelo de regresión lineal, el mejor explorado en la experimentación previa, para predecir la presión sanguínea de los pacientes sanos, así obtener un modelo que estima cuál debiera ser el nivel sanguíneo en base al resto de información del paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mask_norm = class_label_train == 0 \n",
    "model = #choose yor model..\n",
    "model.fit(Xstd_train[mask_norm], reg_label_train[mask_norm])\n",
    "...\n",
    "blood_p_tr = model.predict(Xstd_train) \n",
    "blood_p_te = model.predict(Xstd_test) \n",
    "'''\n",
    "\n",
    "mask_norm = class_label_train == 0 \n",
    "model = Lasso(fit_intercept=True)\n",
    "model.fit(Xstd_train[mask_norm], reg_label_train[mask_norm])\n",
    "...\n",
    "blood_p_tr = model.predict(Xstd_train) \n",
    "blood_p_te = model.predict(Xstd_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> q) Realice una clasificación de los pacientes a través de definir un umbral de decisión óptimo sobre la presión sanguínea estimada por el modelo. Por ejemplo, una cantidad mayor a $p$ es considerado como anormal (enfermo). Para ésto utilice la distribución predicha de este atributo para poder separar correctamente entre los dos tipos de comportamiento, normal (sano) y anormal (enfermo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import seaborn as sns\n",
    "sns.distplot(blood_p_tr[mask_norm], label=\"normal behavior\")\n",
    "sns.distplot(blood_p_tr[~mask_norm], label=\"ill person behavior\")\n",
    "plt.show()\n",
    "def predict_umbr(data, umbral_up, umbral_low):\n",
    "    preds = []\n",
    "    for value in data:\n",
    "        if value > umbral_up or value < umbral_low:\n",
    "            preds.append(1) #presencia\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return np.asarray(preds)\n",
    "pred_train = predict_umbr(blood_p_tr, p_up, p_low)\n",
    "pred_test = predict_umbr(blood_p_te, p_up, p_low)\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(blood_p_tr[mask_norm], label=\"normal behavior\")\n",
    "sns.distplot(blood_p_tr[~mask_norm], label=\"ill person behavior\")\n",
    "plt.show()\n",
    "\n",
    "def predict_umbr(data, umbral_up, umbral_low):\n",
    "    preds = []\n",
    "    for value in data:\n",
    "        if value > umbral_up or value < umbral_low:\n",
    "            preds.append(1) #presencia\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return np.asarray(preds)\n",
    "\n",
    "#https://www.webmd.com/hypertension-high-blood-pressure/qa/what-is-normal-blood-pressure\n",
    "pred_train = predict_umbr(blood_p_tr, 120, 80)\n",
    "pred_test = predict_umbr(blood_p_te, 120, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> r) Mida la calidad de la clasificación entregada a través de la exactitud (*accuracy*) sobre ambos conjuntos. Evalúe si es necesario variar la decisión sobre el umbral del punto anterior. *Recuerde que, al ser un problema binario, el mínimo que se espera es por sobre 50\\%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Score train: \",accuracy_score(class_label_train, pred_train))\n",
    "print(\"Score test: \",accuracy_score(class_label_test, pred_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> s) Compare su *framework* de clasificación con un modelo lineal simple de clasificación binaria como el *perceptrón*, el cual se entrenará para aprender directamente la tarea (de manera supervisada), sin utilizar la información de presión sanguínea. Comente sobre las diferencias, ventajas y desventajas, de cada *approach*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron(fit_intercept=True, eta0=1.0, max_iter=1000, n_jobs=-1)\n",
    "model.fit(Xstd_train, class_label_train)\n",
    "pred_train = model.predict(Xstd_train) \n",
    "pred_test = model.predict(Xstd_test)\n",
    "print(\"Score train: \",accuracy_score(class_label_train, pred_train))\n",
    "print(\"Score test: \",accuracy_score(class_label_test, pred_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> t) Para poder darle una explicación más visual a la clasificación de ambos modelos, y así entender mejor dónde podría estar el error, proyecte los datos en 2 dimensiones. Utilice la técnica de reducción de dimensionalidad **PCA** para representar los datos en las dimensiones deseadas. Comente sobre el comportamiento, puede colorear los datos dado el estado del paciente (enfermedad) y/o la predicción de alguno de los modelos (Perceptrón o con umbral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "d = 2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(Xstd_train)\n",
    "X_pca_train = pca_model.transform(Xstd_train)\n",
    "X_pca_test = pca_model.transform(Xstd_test)\n",
    "plt.scatter(X_pca_train[:,0], X_pca_train[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> u) Vuelve a realizar lo anterior pero con otra técnica de reducción de dimensionalidad, como por ejemplo **ICA** [[3]](#refs). Comente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "d = 2\n",
    "transformer = FastICA(n_components=d, random_state=0)\n",
    "X_ica_train = transformer.fit_transform(Xstd_train)\n",
    "X_ica_test = transformer.fit_transform(Xstd_test)\n",
    "plt.scatter(X_ica_train[:,0], X_ica_train[:,1])\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "d = 2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(Xstd_train)\n",
    "X_pca_train = pca_model.transform(Xstd_train)\n",
    "X_pca_test = pca_model.transform(Xstd_test)\n",
    "plt.scatter(X_pca_train[:,0], X_pca_train[:,1])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> v) ¿Qué tanto se ve afectada la calidad de predicción si se utiliza la representación reducida generada por PCA vs la representación original? ¿Es esperable este fenómeno? ¿Podría mejorar la calidad de predicción? Proponga e implemente un criterio para seleccionar el número de componentes $d$ en PCA. Comente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Estimación de edad de personas\n",
    "El problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante dificil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n",
    "\n",
    "<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con unos datos (imágenes) en el **objetivo** de predecir la **edad** (*target value*) de la persona presente en la imagen. Los datos corresponden a 3640 imágenes de rostros de personas extraídos de la plataforma Flickr, pero, debido a que trabajamos con redes *feed forward*, se trabajará con representaciones de alto nivel, extraídas manualmente (no-aprendibles). Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n",
    "```\n",
    "\n",
    "Se trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:\n",
    "```python\n",
    "import scipy.io as sio\n",
    "mat_file = sio.loadmat(\"event.mat\")\n",
    "```\n",
    "Mientras que para acceder a la información como tal:\n",
    "```python\n",
    "data = mat_file[\"trcoll\"][0][0] # is \"tecoll\" for testing set\n",
    "age_true = data[1] #target\n",
    "...\n",
    "genFeat = data[0]   # Contextual features\n",
    "ffcoefs = data[3]   # Fisherface space\n",
    "faceGist = data[4]  # GIST features\n",
    "...\n",
    "```\n",
    "\n",
    "Para descripción sobre las columnas están en el archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n",
    "```\n",
    "\n",
    "Existen distintas representaciones (descriptores) que usted podrá trabajar y entregársela como *input* a su modelo. Está la libertad de cómo desea trabajar este problema para detectar la edad de la persona, ya sea combinando los descriptores, teniendo un modelo para cada uno, definiendo rangos de edad o cualquier idea que se le ocurra. \n",
    "\n",
    "#### Importante\n",
    "* Recuerde que el conjunto de pruebas está para evaluar su modelo final, **no puede tomar decisiones basadas en este conjunto**. *Sin embargo, Puede generar un conjunto de validación desde el conjunto de entrenamiento o utilizar validación cruzada*.\n",
    "\n",
    "* La métrica de evaluación será MAPE (*Mean Absolute Percetage Error*).\n",
    "```python\n",
    "import numpy as np\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "```\n",
    "* Se evaluará la extensión de su experimentación, la correctitud y su creatividad al desarrollar la actividad.\n",
    "\n",
    "#### --- Bonus ---\n",
    "Si desea comparar la calidad de solución respecto a otros estudiantes podrá realizar un *submission* de sus resultados en el conjunto de pruebas en la plataforma de __[Kaggle](https://www.kaggle.com/c/t1-ml/)__ a través del siguiente __[link](https://www.kaggle.com/t/3f3c4a759ec3482ab06c06ec91187742)__.\n",
    "\n",
    "El archivo de *submission* debe contener una columna de *id* asociado a cada conjunto de pruebas, iniciando en 1, se puede generar de la siguiente manera:\n",
    "```python\n",
    "ids = np.arange(1, 1+y_pred.shape[0]).reshape(-1,1)\n",
    "sub_est = np.concatenate([ids, y_pred], axis=-1)\n",
    "import pandas as pd\n",
    "df_aux = pd.DataFrame(sub_est, columns=[\"id\",\"age\"])\n",
    "df_aux.to_csv(\"test_estimation.csv\", index=False)\n",
    "```\n",
    "\n",
    "> Para los 3 primeros lugares se otorgará 5, 10 y 15 puntos respectivos en su nota final de esta tarea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Hastie, T.; Tibshirani, R., Friedman, J. (2009), *The Elements of Statistical Learning*, Second Edition.\n",
    "Springer New York Inc.  \n",
    "[2] Ethem Alpaydin. *Machine Learning*. 2014.  \n",
    "[3] Hyvärinen, A., & Oja, E. (2000). *Independent component analysis: algorithms and applications*. Neural networks, 13(4-5), 411-430."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
